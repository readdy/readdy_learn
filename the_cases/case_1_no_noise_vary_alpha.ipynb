{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import pickle\n",
    "\n",
    "import readdy_learn.analyze.analyze as ana\n",
    "import readdy_learn.analyze.basis as basis\n",
    "from pathos.multiprocessing import Pool\n",
    "\n",
    "import pynumtools.kmc as kmc\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (16, 13)\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as ss\n",
    "from readdy_learn.example.regulation_network import RegulationNetwork\n",
    "from readdy_learn.example.regulation_network import sample_lsq_rates\n",
    "from readdy_learn.example.regulation_network import sample_along_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try to generate reg network s.t. LSQ does not work properly\n",
    "\n",
    "### Case 1\n",
    "- LSQ fits well but doesnt necessarily recover the rates (varying $\\alpha$)\n",
    "- In the limit of low noise (and same initial conditions), the least squares solution (almost) recovers almost the right reactions (sparsity pattern). Vary hyperparameters (alpha, ~~lambda~~)\n",
    "- use more basis functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- timestep = $8\\cdot 10^{-3}$: seems O.K.\n",
    "- timestep = $6\\cdot 10^{-3}$: lsq still works reasonably well\n",
    "- timestep = $12 \\cdot 10^{-3}$: lsq begins to get worse\n",
    "    - this almost works, probably need a few more frames\n",
    "- timestep = $24 \\cdot 10^{-3}$: lsq picks up on processes that are definitely not there, ignores some of the correct ones\n",
    "    - could not reproduce correct rates with lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_l1_errors(results, cutoff=0.):\n",
    "    l1_errors = []\n",
    "    l1_std = []\n",
    "    keys_sorted = np.array([k for k in sorted(results.keys())])\n",
    "    for key in keys_sorted:\n",
    "        # shape: (n_realizations, basis funs)\n",
    "        rates = np.array(results[key])\n",
    "        # build difference w correct rates\n",
    "        ratesdiff = np.abs(np.array([r - regulation_network.desired_rates for r in rates]))\n",
    "        l1norms = np.array([np.sum(x) for x in ratesdiff])\n",
    "        l1_errors.append(np.mean(l1norms))\n",
    "        l1_std.append(np.std(l1norms))\n",
    "    l1_errors = np.array(l1_errors)\n",
    "    l1_std = np.array(l1_std)\n",
    "    plt.fill_between(keys_sorted, l1_errors-l1_std, l1_errors+l1_std,\n",
    "                     color='b', alpha=.5)\n",
    "    #plt.errorbar(keys, l2_mean, yerr=l2_std)\n",
    "    plt.plot(keys_sorted, l1_errors)\n",
    "    plt.xscale('log')\n",
    "    #plt.yscale('log')\n",
    "    plt.xlabel(r'$\\alpha$')\n",
    "    plt.ylabel('L1 error')\n",
    "    ix = np.argmin(l1_errors)\n",
    "    return l1_errors[ix], ix\n",
    "def get_regulation_network(timestep):\n",
    "    regulation_network = RegulationNetwork()\n",
    "    regulation_network.timestep = timestep\n",
    "    regulation_network.realisations = 1.\n",
    "    regulation_network.noise_variance = 0.\n",
    "    regulation_network.initial_states = [regulation_network.initial_states[1]]\n",
    "    analysis = regulation_network.generate_analysis_object(fname_prefix='case_1', fname_postfix='0')\n",
    "    for i in range(len(regulation_network.initial_states)):\n",
    "        analysis.generate_or_load_traj_lma(i, regulation_network.target_time,\n",
    "                                           noise_variance=regulation_network.noise_variance,\n",
    "                                           realizations=regulation_network.realisations)\n",
    "        shape = analysis.trajs[i].counts.shape\n",
    "        print(\"n_frames={}, n_species={}\".format(*shape))\n",
    "    regulation_network.compute_gradient_derivatives(analysis, persist=False)\n",
    "    return regulation_network\n",
    "def do(timestep, fname):\n",
    "    regulation_network = get_regulation_network(timestep)\n",
    "    alphas = np.logspace(-6, -4, num=200)\n",
    "    result = sample_along_alpha(regulation_network, alphas=alphas)\n",
    "    lsq_rates = analysis.least_squares(0, tol=1e-16, recompute=True, persist=False, verbose=False)\n",
    "    ana.plot_rates_bar(regulation_network.desired_rates, lsq_rates)\n",
    "    plt.title('LSQ')\n",
    "    plt.show()\n",
    "    error, ix = plot_l1_errors(result)\n",
    "    plt.show()\n",
    "    ana.plot_rates_bar(regulation_network.desired_rates, np.array(result[alphas[ix]]).squeeze())\n",
    "    plt.title('regularized')\n",
    "    plt.show()\n",
    "    \n",
    "    data = {\n",
    "        'regularized_rates': result,\n",
    "        'lsq_rates': lsq_rates\n",
    "    }\n",
    "    \n",
    "    print(\"minimal l1 error: {} (ix {})\".format(error, ix))\n",
    "    with open(fname, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "def show_results(fname):\n",
    "    print(\"loading results from {}....\".format(fname))\n",
    "    regulation_network = get_regulation_network(1e-3)\n",
    "    alphas = np.logspace(-6, -4, num=200)\n",
    "    \n",
    "    with open(fname, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    result = data['regularized_rates']\n",
    "    lsq_rates = data['lsq_rates']\n",
    "    \n",
    "    ana.plot_rates_bar(regulation_network.desired_rates, lsq_rates)\n",
    "    plt.title('LSQ')\n",
    "    plt.show()\n",
    "    error, ix = plot_l1_errors(result)\n",
    "    plt.show()\n",
    "    ana.plot_rates_bar(regulation_network.desired_rates, np.array(result[alphas[ix]]).squeeze())\n",
    "    plt.title('regularized')\n",
    "    plt.show()\n",
    "    print(\"minimal l1 error: {} (ix {})\".format(error, ix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dt = 9e-3, 334 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_frames=334, n_species=9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cca78d4cb1b540fdbeb9d8dced7261c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(HBox(children=(Label(value='sample for alphas 0'),), layout=Layout(max_width='35%', min_width='35%')), HBox(children=(IntProgress(value=0, max=200), HTML(value='')), layout=Layout(padding='0 0 0 20px'))), layout=Layout(display='flex', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "do(9e-3, 'case_1_dt_9e-3.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dt = 8e-3, 375 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do(8e-3, 'case_1_dt_8e-3.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dt = 12e-3, 250 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do(12e-3, 'case_1_dt_12e-3.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dt = 16e-3, 188 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do(16e-3, 'case_1_dt_16e-3.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dt = 24e-3, 125 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do(24e-3, 'case_1_dt_24e-3.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
