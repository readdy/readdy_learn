\documentclass[oneside, abstracton, titlepage]{scrartcl}

\usepackage[left=2.5cm,right=2.6cm,top=3cm,bottom=3cm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[intlimits]{amsmath}
\usepackage{amssymb}
\usepackage{color}
\usepackage{xcolor}
\usepackage{subcaption}
\usepackage[version=4]{mhchem}

\usepackage{graphicx}

\newsavebox{\selvestebox}
\newenvironment{colbox}[1]
{\newcommand\colboxcolor{#1}%
	\begin{lrbox}{\selvestebox}%
		\begin{minipage}{\dimexpr\columnwidth-2\fboxsep\relax}}
		{\end{minipage}\end{lrbox}%
	\begin{center}
		\colorbox[HTML]{\colboxcolor}{\usebox{\selvestebox}}
\end{center}}
\newcommand\restr[2]{{% we make the whole thing an ordinary symbol
		\left.\kern-\nulldelimiterspace % automatically resize the bar with \right
		#1 % the function
		\vphantom{\big|} % pretend it's a little taller at normal size
		\right|_{#2} % this is the delimiter
}}

\begin{document}
	\title{Discovering governing reactions from concentration data}
	\maketitle

	\section{Introduction}
	When presented with a time series of possibly noisy non-equilibrium concentration fluctuations of some species as output of, e.g., measurements from experiments or simulations that were parameterized by microscopic rates, one can ask for the corresponding macroscopic rates and a generating reaction network.
	In this paper we present an application of the shallow learning method SINDy \cite{Brunton2015}. By sparse regression, it is able to identify generating nonlinear dynamics in data that stems from dynamical systems. The parsimonious nature of the results avoids overfitting and provides interpretability.
	In our application we, as opposed to the original method, do not only look for macroscopic rates of net species change but investigate the specific reactions that might have lead to the observations.
	We demonstrate the algorithm on three toy problems: When there is no noise in the data we can find all relevant processes of the ground truth. If there is noise in the data we converge to the correct reaction network and rates with decreasing noise. The last toy problem deals with the case that there are two realizations with different initial conditions, for which can also show convergence to the correct model with decreasing levels of noise.

	\section{The method}
	The underlying model is a law of mass action type dynamical system. To this end, let $S$ be the number of species, then the observed concentration at a time $t$ can be represented by a vector
	\begin{align}
	\mathbf{x}(t)=\begin{pmatrix}
	x_1(t)\\ \vdots \\ x_S(t)
	\end{pmatrix}\in \mathbb{R}^S.
	\end{align}
	Further, one can choose $R$ possible ansatz reactions with their respective reaction functions
	\begin{align}
	\textbf{y}_r(\textbf{x}(t))=\begin{pmatrix}
	y_{r,1}(\textbf{x}(t)) \\ \vdots \\ y_{r,S}(\textbf{x}(t))
	\end{pmatrix},\quad r=1,\ldots,R,
	\end{align}
	so that the change of concentration for species $i$ at time $t$ is represented by the dynamical system
	\begin{align}
	\dot{\textbf{x}}_i(t) = \sum_{r=1}^{R}y_{r,i}(\textbf{x}(t))\xi_r,\quad i=1,\ldots, S,
	\label{method:the-system}\end{align}
	where $\xi_r$ are the to-be estimated macroscopic rates.

	When presented with a time series consisting of $T$ observations at points in time $t_1<\ldots < t_T$, the data can be represented as a matrix
	\begin{align}
	\textbf{X} = \begin{pmatrix}
		x_1(t_1) & x_2(t_1) & \cdots & x_S(t_1) \\
		x_1(t_2) & x_2(t_2) & \cdots & x_S(t_2) \\
		\vdots   & \vdots   & \ddots & \vdots   \\
		x_1(t_T) & x_2(t_T) & \cdots & x_S(t_T)
	\end{pmatrix} \in \mathbb{R}^{T\times S}.
	\end{align}
	Given this matrix, a library $\Theta(\textbf{X}) = \begin{pmatrix} \theta_1(\textbf{X}) & \theta_2(\textbf{X}) & \cdots & \theta_R(\textbf{X}) \end{pmatrix}$ of $R$ ansatz reactions can be proposed with corresponding reaction functions
	\begin{align}
		\theta_r(\textbf{X}) = \begin{pmatrix}
		\textbf{y}_r(\textbf{X}_1)^T \\ \vdots \\ \textbf{y}_r(\textbf{X}_T)^T
		\end{pmatrix}\in \mathbb{R}^{T\times S},\quad r=1,\ldots,R,
	\label{method:the-reactions}\end{align}
	where $\textbf{X}_i$ denotes the $i$-th row in $\textbf{X}$. Applying the concentration trajectory to the library yields $\Theta(\textbf{X})\in\mathbb{R}^{T\times S\times R}$. Following the approach of SINDy, the goal is to find coefficients $\Xi = \begin{pmatrix} \xi_1 & \xi_2 & \cdots & \xi_R
	\end{pmatrix}^T$, so that
	\begin{align}
	\dot{\textbf{X}} = \Theta(\textbf{X})\Xi = \sum_{r=1}^{R}\theta_r(\textbf{X})\xi_r.
	\end{align}
	In particular, the system is linear in the coefficients $\Xi$, which makes regression tools such as elastic net regularization \cite{Zou2005} applicable. To this end, one can consider the minimization problem to find $\hat{\Xi}$ such that
	\begin{align}
		\hat{\Xi} = \underset{\Xi}{\arg\min}\left( \frac{1}{2T}\left\| \dot{\textbf{X}} - \Theta(\textbf{X})\Xi \right\|_F^2 + \alpha\lambda\|\Xi\|_1 + \alpha(1-\lambda)\|\Xi\|_2^2 \right) \quad \text{subject to }\Xi \geq 0,
	\label{method:minimizationproblem}\end{align}
	where $\|\cdot\|_F$ denotes the Frobenius norm, $\lambda\in[0,1]$ a hyperparameter that interpolates linearly between LASSO \cite{Tibshirani1996, Hastie2009} and Ridge \cite{Hoerl1} methods, and $\alpha\geq 0$ is a hyperparameter that, depending on $\lambda$, can induce sparsity and give preference to smaller solutions in the $L_1$ or $L_2$ sense.

	When presented with multiple trajectories the data matrices $\mathbf{X}$ and $\dot{\mathbf{X}}$ can be stacked and inserted into the minimization problem.
	
	For $\alpha=0$ the minimization problem reduces to constrained least-squares. In order to solve (\ref{method:minimizationproblem}) the sequential least-squares minimizer SLSQP \cite{Kraft1988} is applied via the software package SciPy \cite{SciPy}. Since only the concentration data $\mathbf{X}$ is available but not its temporal derivative $\dot{\mathbf{X}}$, it is approximated numerically by second order finite differences with the exception of boundary data.

    \section{Example system: Regulation of gene expression}\label{sec:generegulation}

    To demonstrate the method a gene-regulatory network is estimated from time series of molecule-concentrations. The data of is generated by integrating the law of mass action equations of the underlying model and adding Gaussian noise.
    
    To this end, let $A$, $B$, and $C$ be three species of proteins which are being translated from a corresponding mRNA molecule. Each mRNA in turn has a corresponding DNA which it is transcribed from. The proteins and mRNA molecules decay over time whereas the DNA concentration remains constant.
    
    For each of the three species one can formulate the following basic reactions
	\begin{align*}
        \ce{ DNA_i } & \ce{ -> DNA_i + mRNA_i } &\text{(transcription)}, \\
        \ce{ mRNA_i } & \ce{ -> mRNA_i + Protein_i } &\text{(translation)}, \\
        \ce{ mRNA_i } & \ce{ -> } \emptyset &\text{(decay of mRNA)}, \\
        \ce{ Protein_i } & \ce{ -> } \emptyset &\text{(decay of Protein)},
    \end{align*}
    for $i=A,B,C$.

    The protein concentrations of $A$, $B$, and $C$ regulate each other in a negative way by hindering the transcription process. In the law of mass action model we account for this by a reaction. A repression of species $j$ by species $i$ can be modeled as
    \begin{equation*}
        \ce{ Protein_i + mRNA_j -> Protein_i } \quad \text{(regulation by repression)}.
    \end{equation*}

    In our example proteins of type $A$ regulate the mRNA$_\mathrm{B}$ molecules, proteins of type $B$ regulate the mRNA$_\mathrm{A}$ molecules and proteins of type $C$ regulate the mRNA$_\mathrm{A}$ molecules. The network of all species and reactions is depicted in Figure \ref{fig:network}. This serves as reference model to generate the time series of concentrations.
    \begin{figure}
        \centering
        \includegraphics[width=.5\textwidth]{./figures_tex/gene_regulation_full.pdf}
        \caption{The regulation network example described in Section \ref{sec:generegulation}. Each circle depicts a species, each arrow corresponds to one reaction. The red arrows describe the regulatory network which generates the example data.}
        \label{fig:network}
    \end{figure}

	\section{Results}\label{sec:results}
	
	The proposed estimation method is designed to find reaction networks and rates from experimental data. In the following the method is applied to data generated from the example described in Section \ref{sec:generegulation}.

	First it is assumed that the concentration data can be obtained without noise and it is shown that while the minimization problem (\ref{method:minimizationproblem}) without regularization, i.e., $\alpha=0$, yields rates that fit well to the input data, the original rates cannot be recovered while adding $L_1$ regularization and a certain cutoff improves the situation and the original model can be recovered.
	
	In Section \ref{sec:case-2} the example data contains additive Gaussian noise. It is assumed that the initial state can be reproduced exactly and one has several measurements. It is shown that in the limit of small noise one can obtain a good fit and regularization helps in the reliability of the estimated reaction rates.
	
	The last example is described in Section \ref{sec:case-3} and can be seen as an extension of the situation in Section \ref{sec:case-3} to multiple initial conditions.
	
	%measurement scenarios are considered that differ in how many time series are available and the level of noise that the data is subject to:
	%\begin{enumerate}
	%	\item The initial state of the measurement apparatus can be reproduced exactly. There is only one set of generating reaction rates. Each frame of a time series is subject to noise. The outcome of this scenario is one time series of concentrations with a certain noise-level.
	%	\item The process is observed multiple times. The initial state of the measurement apparatus differs in each observation. The outcome of this scenario is multiple time series each with a certain noise level and different initial states.
	%\item The process is observed multiple times. The initial state of the measurement apparatus differs in each observation. Additionally the generating reaction rates differ slightly in each observation. The outcome of this scenario is multiple time series each with a given noise level, different initial states and slightly perturbed underlying reaction rates.
	%\end{enumerate}

	\subsection{The noiseless case}\label{sec:case-1}
	
	In this section noiseless data generated from the law of mass action system described in Section \ref{sec:generegulation} is applied to the minimization problem (\ref{method:minimizationproblem}). When setting the hyperparameter $\alpha=0$ one obtains least squares regression with a constraint on the non-negativity of the estimated reaction rates.
	
	\begin{figure}
		\centering
		\includegraphics[width=.9\textwidth]{./figures_tex/bubbles}
		\caption{Generating and estimated reaction rates in the situation of Section \ref{sec:case-1}. The y and x axes contain reaction educts and products, respectively. The black outlines denote the reactions with which the system was generated and the area of the circles scales linearly with the reaction rate. The blue circles are least squares estimated reaction rates and the orange circles depict rates which were obtained by some $\alpha>0$ in the minimization problem (\ref{method:minimizationproblem}). If a certain rate was estimated in both cases, two wedges instead of once circle as displayed.}
		\label{fig:case-1-sparsity-pattern}
	\end{figure}

	When applying no regularization, one can observe in Figure \ref{fig:case-1-sparsity-pattern} that the sparsity pattern does not match the generating reaction network and the reaction responsible for the decay of $\mathrm{A}$ particles is completely ignored. For a suitable choice of the hyperparameter $\alpha > 0$ and a cutoff one can obtain a sparser solution and also recover the decay reaction as indicated by the red rings in the figure.
	
	\subsection{Multiple measurements at the same noise level}\label{sec:case-2}
	
	\begin{itemize}
		\item Same setup as in Section \ref{sec:case-1}
		\item Cross validation with a shuffle split and 3 folds
		\item comparison to LSQ: LSQ unreliable
		\item in the limit of small noise one gets a good fit
		\item obtain cutoff in noise free case, compute failure rate (number of false positives and negatives)
	\end{itemize}

	\subsection{Multiple initial conditions}\label{sec:case-3}
	
	\begin{itemize}
		\item extend situation of Section \ref{sec:case-3} to multiple initial conditions
		\item compute failure rate
	\end{itemize}
    
	\section{Conclusion}
	\begin{colbox}{F8E0E0}
		todo
	\end{colbox}
	In this work we have successfully applied and extended the SINDy method to not only parsimoniously detect potentially nonlinear terms in a dynamical system from noisy data, but also yield, in this case, a sparse set of rates with respect to generating reactions (\ref{method:the-reactions}).

	In two examples it was demonstrated that despite noisy data and unavailable derivative measurements, a parsimonious generating reaction network that is qualitatively able to explain the observed data can be estimated.
	In particular it was shown in the first example that if there is no ambiguity in the underlying model and ansatz reaction library, the actual rates can be recovered with decreasing time step, i.e., increasing resolution of the jump process.
	In the second example we could obtain an even simpler model than what was used to generate data by making use of sparse regression and cross-validation.

	\newpage
% 	\bibliographystyle{alpha}
	\bibliographystyle{abbrv}
	\bibliography{bibliography.bib}
	\newpage	
	\section{Appendix}\label{sec:appendix}
	\begin{colbox}{F8E0E0}
		the reaction table needs an update
	\end{colbox}
	\begin{table}[h]
		\centering
		\scalebox{0.7}{
			\begin{tabular}{rclcc}
				\multicolumn{3}{c}{Reaction} & rate & description \\ \hline\noalign{\vskip .1cm}
				$\ce{DNA_A}$ &$\ce{->}$& $\ce{DNA_A + mRNA_A }$ & $k_1 = 1.8$ & transcription of $\ce{mRNA_A}$\\
				$\ce{mRNA_A}$ &$\ce{->}$& $\ce{mRNA_A + A}$ & $k_2 = 2.1$ & translation of $\ce{A}$ proteins\\
				$\ce{mRNA_A}$ &$\ce{->}$& $\ce{\emptyset}$ & $k_3 = 1.3$ & $\ce{mRNA_A}$ decay\\
				$\ce{A}$ &$\ce{->}$& $\ce{\emptyset }$ & $k_4 = 1.5$ & decay of $\ce{A}$ proteins\\
				$\ce{DNA_B}$ &$\ce{->}$& $\ce{DNA_B + mRNA_B }$ & $k_5 = 2.2$ & transcription of $\ce{mRNA_B}$\\
				$\ce{mRNA_B}$ &$\ce{->}$& $\ce{mRNA_B + B}$ & $k_6 = 2.0$ & translation of $\ce{B}$ proteins\\
				$\ce{mRNA_B}$ &$\ce{->}$& $\ce{\emptyset }$ & $k_7 = 2.0$ & $\ce{mRNA_B}$ decay\\
				$\ce{B}$ &$\ce{->}$& $\ce{\emptyset }$ & $k_8 = 2.5$ & decay of $\ce{B}$ proteins\\
				$\ce{DNA_C}$ &$\ce{->}$& $\ce{DNA_C + mRNA_C }$ & $k_9 = 3.2$ & transcription of $\ce{mRNA_C}$\\
				$\ce{mRNA_C}$ &$\ce{->}$& $\ce{mRNA_C + C}$ & $k_{10} = 3.0$ & translation of $\ce{C}$ proteins\\
				$\ce{mRNA_C}$ &$\ce{->}$& $\ce{\emptyset }$ & $k_{11} = 2.3$ & $\ce{mRNA_C}$ decay\\
				$\ce{C}$ &$\ce{->}$& $\ce{\emptyset }$ & $k_{12} = 2.5$ & decay of $\ce{C}$ proteins\\
				$\ce{mRNA_A + A}$ &$\ce{->}$& $A$ & $k_{13} = 0$ & self regulation of $\ce{A}$ proteins\\
				$\ce{mRNA_B + B}$ &$\ce{->}$& $B$ & $k_{14} = 0$ & self regulation of $\ce{B}$ proteins\\
				$\ce{mRNA_C + C}$ &$\ce{->}$& $C$ & $k_{15} = 0$ & self regulation of $\ce{C}$ proteins\\
				$\ce{mRNA_B + A}$ &$\ce{->}$& $A$ & $k_{16} = 0$ & cyclic regulation of $\ce{A}$ proteins\\
				$\ce{mRNA_C + B}$ &$\ce{->}$& $B$ & $k_{17} = 0$ & cyclic regulation of $\ce{B}$ proteins\\
				$\ce{mRNA_A + C}$ &$\ce{->}$& $C$ & $k_{18} = 0$ & cyclic regulation of $\ce{C}$ proteins\\
				$\ce{mRNA_C + A}$ &$\ce{->}$& $A$ & $k_{16} = 6.0$ & cyclic regulation of $\ce{A}$ proteins\\
				$\ce{mRNA_B + C}$ &$\ce{->}$& $C$ & $k_{17} = 4.0$ & cyclic regulation of $\ce{C}$ proteins\\
				$\ce{mRNA_A + B}$ &$\ce{->}$& $B$ & $k_{18} = 3.0$ & cyclic regulation of $\ce{B}$ proteins\\
				$\ce{mRNA_A + A}$ &$\ce{->}$& $\ce{mRNA_A}$ & $k_{19} = 0$ & artificial fusion\\
				$\ce{mRNA_B + B}$ &$\ce{->}$& $\ce{mRNA_B}$ & $k_{20} = 0$ & artificial fusion\\
				$\ce{mRNA_C + C}$ &$\ce{->}$& $\ce{mRNA_C}$ & $k_{21} = 0$ & artificial fusion\\
				$\ce{mRNA_A + B}$ &$\ce{->}$& $\ce{mRNA_A}$ & $k_{22} = 0$ & artificial fusion\\
				$\ce{mRNA_B + C}$ &$\ce{->}$& $\ce{mRNA_B}$ & $k_{23} = 0$ & artificial fusion\\
				$\ce{mRNA_C + A}$ &$\ce{->}$& $\ce{mRNA_C}$ & $k_{24} = 0$ & artificial fusion\\
				$\ce{mRNA_A + C}$ &$\ce{->}$& $\ce{mRNA_A}$ & $k_{25} = 0$ & artificial fusion\\
				$\ce{mRNA_B + A}$ &$\ce{->}$& $\ce{mRNA_B}$ & $k_{26} = 0$ & artificial fusion\\
				$\ce{mRNA_C + B}$ &$\ce{->}$& $\ce{mRNA_C}$ & $k_{27} = 0$ & artificial fusion\\
				$\ce{A + A}$ &$\ce{->}$& $\ce{A}$ & $k_{28} = 0$ & $\ce{A}$ regulates $\ce{A}$\\
				$\ce{B + B}$ &$\ce{->}$& $\ce{B}$ & $k_{29} = 0$ & $\ce{B}$ regulates $\ce{B}$\\
				$\ce{C + C}$ &$\ce{->}$& $\ce{C}$ & $k_{30} = 0$ & $\ce{C}$ regulates $\ce{C}$\\
				$\ce{B + A}$ &$\ce{->}$& $\ce{A}$ & $k_{31} = 0$ & artificial fusion between proteins\\
				$\ce{C + B}$ &$\ce{->}$& $\ce{B}$ & $k_{32} = 0$ & artificial fusion between proteins\\
				$\ce{A + C}$ &$\ce{->}$& $\ce{C}$ & $k_{33} = 0$ & artificial fusion between proteins\\
				$\ce{C + A}$ &$\ce{->}$& $\ce{A}$ & $k_{34} = 0$ & artificial fusion between proteins\\
				$\ce{B + C}$ &$\ce{->}$& $\ce{C}$ & $k_{35} = 0$ & artificial fusion between proteins\\
				$\ce{A + B}$ &$\ce{->}$& $\ce{B}$ & $k_{36} = 0$ & artificial fusion between proteins\\
				$\ce{A}$ &$\ce{->}$& $\ce{B}$ & $k_{37} = 0$ & artificial conversion between proteins\\
				$\ce{B}$ &$\ce{->}$& $\ce{C}$ & $k_{38} = 0$ & artificial conversion between proteins\\
				$\ce{C}$ &$\ce{->}$& $\ce{A}$ & $k_{39} = 0$ & artificial conversion between proteins\\
				$\ce{A}$ &$\ce{->}$& $\ce{C}$ & $k_{40} = 0$ & artificial conversion between proteins\\
				$\ce{C}$ &$\ce{->}$& $\ce{B}$ & $k_{41} = 0$ & artificial conversion between proteins\\
				$\ce{B}$ &$\ce{->}$& $\ce{A}$ & $k_{42} = 0$ & artificial conversion between proteins
			\end{tabular}
		}
		\caption{Full set of ansatz reactions $\Theta$ used in Section \ref{sec:examples}.}
		\label{tab:reaction-library}
	\end{table}
\end{document}
